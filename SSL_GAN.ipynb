{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSL-GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1f8XB7A5gQipyPHD5inHMqdb4ZDh_Qzlx",
      "authorship_tag": "ABX9TyOjv40T13+6tSX0byQ9zm5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayaanzhaque/DeepRacer2020/blob/master/SSL_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPziPBDQpgN7",
        "colab_type": "text"
      },
      "source": [
        "# GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaW_Qyu0HZII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pdb\n",
        "\n",
        "# torch imports\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch import optim,nn\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "\n",
        "class DCGAN_generator(nn.Module):\n",
        "  \"\"\"\n",
        "\n",
        "  Attributes\n",
        "  ----------\n",
        "    ngpu : int\n",
        "      The number of available GPU devices\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, ngpu):\n",
        "    \"\"\"Init function\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "      ngpu : int\n",
        "        The number of available GPU devices\n",
        "\n",
        "    \"\"\"\n",
        "    super(DCGAN_generator, self).__init__()\n",
        "    self.ngpu = ngpu\n",
        "        \n",
        "    # just to test - will soon be args\n",
        "    nz = 100 # noise dimension\n",
        "    ngf = 64 # number of features map on the first layer\n",
        "    nc = 3 # number of channels\n",
        "\n",
        "    self.main = nn.Sequential(\n",
        "      # input is Z, going into a convolution\n",
        "      nn.ConvTranspose2d(     nz, ngf * 4, 4, 1, 0, bias=False),\n",
        "      nn.BatchNorm2d(ngf * 4),\n",
        "      nn.ReLU(True),\n",
        "      # state size. (ngf*8) x 4 x 4\n",
        "      nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ngf * 2),\n",
        "      nn.ReLU(True),\n",
        "      # state size. (ngf*4) x 8 x 8\n",
        "      nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ngf),\n",
        "      nn.ReLU(True),\n",
        "      # state size. (ngf*2) x 16 x 16\n",
        "      nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "      nn.Tanh()\n",
        "      # state size. (nc) x 64 x 64\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    \"\"\"Forward function\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input : :py:class:`torch.Tensor`\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    :py:class:`torch.Tensor`\n",
        "      the output of the generator (i.e. an image)\n",
        "\n",
        "    \"\"\"\n",
        "    #if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
        "    #  output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "    #else:\n",
        "    #  output = self.main(input)\n",
        "    \n",
        "    # let's assume that we will never face the case where more than a GPU is used ...\n",
        "    output = self.main(input)\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "class DCGAN_discriminator(nn.Module):\n",
        "  \"\"\" \n",
        "\n",
        "  Attributes\n",
        "  ----------\n",
        "    ngpu : int\n",
        "      The number of available GPU devices\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, ngpu):\n",
        "    \"\"\"Init function\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "      ngpu : int\n",
        "        The number of available GPU devices\n",
        "\n",
        "    \"\"\"\n",
        "    super(DCGAN_discriminator, self).__init__()\n",
        "    self.ngpu = ngpu\n",
        "        \n",
        "        \n",
        "    # just to test - will soon be args\n",
        "    ndf = 64\n",
        "    nc = 3\n",
        "       \n",
        "    self.main = nn.Sequential(\n",
        "      nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ndf),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "      nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ndf * 2),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      # state size. (ndf*4) x 8 x 8\n",
        "      nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "      nn.BatchNorm2d(ndf * 4),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      # state size. (ndf*8) x 4 x 4\n",
        "      nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    \"\"\"Forward function\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input : :py:class:`torch.Tensor`\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    :py:class:`torch.Tensor`\n",
        "      the output of the generator (i.e. an image)\n",
        "\n",
        "    \"\"\"\n",
        "    #if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
        "    #  output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "    #else:\n",
        "    #  output = self.main(input)\n",
        "    \n",
        "    # let's assume that we will never face the case where more than a GPU is used ...\n",
        "    output = self.main(input)\n",
        "\n",
        "    return output.view(-1, 1).squeeze(1)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "batch_size = 64\n",
        "trainset = datasets.SVHN(\"/content\", split='train', download = True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2,)\n",
        "\n",
        "testset = datasets.SVHN(\"/content\", split='test', download = True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# define device \n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# data for plotting purposes\n",
        "generatorLosses = []\n",
        "discriminatorLosses = []\n",
        "\n",
        "#training starts\n",
        "\n",
        "epochs = 25\n",
        "\n",
        "input_size = 32\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "\n",
        "# models\n",
        "netG = DCGAN_generator(1)\n",
        "netD = DCGAN_discriminator(1)\n",
        "\n",
        "netG.to(device)\n",
        "netD.to(device)\n",
        "\n",
        "print(netG)\n",
        "\n",
        "# optimizers \n",
        "optD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999)) \n",
        "optG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999)) \n",
        "\n",
        "input_length = int(math.log(128, 2))\n",
        "\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    \n",
        "    dataiter = iter(trainloader)\n",
        "    inputs, labels = dataiter.next()\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    tmpBatchSize = len(labels)  \n",
        "\n",
        "    # create label arrays \n",
        "    true_label = torch.ones(tmpBatchSize, 1, device=device)\n",
        "    fake_label = torch.zeros(tmpBatchSize, 1, device=device)\n",
        "    # print(inputs)\n",
        "    # print(labels)\n",
        "\n",
        "    # generate fake images // im struggling here as well\n",
        "    r = torch.randn(tmpBatchSize, 100, 1, 1, device=device) #not sure if this is correct but it isnt giving errors\n",
        "    # print(r)\n",
        "    fakeImageBatch = netG(r)\n",
        "    # print(fakeImageBatch)\n",
        "\n",
        "    # # visualize the fake image \n",
        "    # plt.subplot(1,2,2)\n",
        "    # plt.axis(\"off\")\n",
        "    # plt.title(\"Fake Images\")\n",
        "    # plt.imshow(np.transpose(vutils.make_grid(fakeImageBatch, padding=2, normalize=True)))\n",
        "    # plt.show()\n",
        "\n",
        "    real_cpu = data[0].to(device)\n",
        "    batch_size = real_cpu.size(0)\n",
        "    # print(batch_size)\n",
        "\n",
        "    # train generator on real images\n",
        "    # predictionsReal = netD(real_cpu).view(-1)\n",
        "    predictionsReal = netD(inputs)\n",
        "    lossDiscriminator = loss(predictionsReal, true_label) #labels = 1\n",
        "    lossDiscriminator.backward(retain_graph = True)\n",
        "\n",
        "    # train generator on fake images\n",
        "    predictionsFake = netD(fakeImageBatch)\n",
        "    lossFake = loss(predictionsFake, fake_label)  #labels = 0\n",
        "    lossFake.backward(retain_graph= True)\n",
        "    optD.step() # update discriminator parameters    \n",
        "\n",
        "    # train generator \n",
        "    optG.zero_grad()\n",
        "    predictionsFake = netD(fakeImageBatch)\n",
        "    # batch_size = 8192\n",
        "    # true_label = torch.full((batch_size,), real_label, device=device)\n",
        "    lossGenerator = loss(predictionsFake, true_label) #labels = 1\n",
        "    lossGenerator.backward(retain_graph = True)\n",
        "    optG.step()\n",
        "\n",
        "    # reset the gradients\n",
        "    optD.zero_grad()\n",
        "    optG.zero_grad()\n",
        "\n",
        "    # save losses for graphing\n",
        "    generatorLosses.append(lossGenerator.item())\n",
        "    discriminatorLosses.append(lossDiscriminator.item())\n",
        "\n",
        "    # # save generated images \n",
        "    if(i % 100 == 0):\n",
        "       gridOfFakeImages = torchvision.utils.make_grid(fakeImageBatch.cpu())\n",
        "       torchvision.utils.save_image(gridOfFakeImages, \"/content/gridOfFakeImages/\" + str(epoch) + '_' + str(i) + '.png')\n",
        "\n",
        "  print(\"Epoch \" + str(epoch) + \"Complete\")\n",
        "  print(\"Generator Loss: \" + str(lossGenerator))\n",
        "  print(\"Discriminator Loss: \" + str(lossDiscriminator))\n",
        "\n",
        "def validate():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "        100 * correct / total))\n",
        "\n",
        "#save models\n",
        "torch.save(netG, \"netG.h5\")\n",
        "torch.save(netD, \"netD.h5\")\n",
        "\n",
        "# plot losses\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Loss of Models\")\n",
        "plt.plot(generatorLosses,label=\"Generator\")\n",
        "plt.plot(discriminatorLosses,label=\"Discriminator\")\n",
        "plt.xlabel(\"Batches\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxtKmRV3xFyH",
        "colab_type": "text"
      },
      "source": [
        "Tasks\n",
        "1. Train a Working GAN (done)\n",
        "2. Train a general classifer (Train the same classifer at different dataset sizes, plot its datasize vs accuracy)\n",
        "3. Train a classifier that uses the smaller dataset sizes + the generated images \n",
        "4. Export accuracy vs dataset size into a different file\n",
        "5. plot the data from the file, see the difference in accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baEYxXC5pmRS",
        "colab_type": "text"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb_01A1i8NZr",
        "colab_type": "text"
      },
      "source": [
        "Classifier with different dataset sizes and generated images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiC1FN2n8w5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2870ac3e-1131-43ba-8186-040fcc7d9611"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pdb\n",
        "\n",
        "# torch imports\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch import optim,nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# model\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "        self.embDim = 128 * block.expansion\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 128, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(128 * block.expansion, num_classes)\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        emb = out.view(out.size(0), -1)\n",
        "        out = self.linear(emb)\n",
        "        return out, emb\n",
        "    def get_embedding_dim(self):\n",
        "        return self.embDim\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "#data preprocessing\n",
        "\n",
        "file = open(\"modelData.txt\", \"w\")\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "generatedImagesRoot = \"/content/drive/My Drive/Colab Notebooks/gridOfFakeImages\"\n",
        "\n",
        "batch_size = 64\n",
        "trainset = datasets.SVHN(\"/content\", split='train', download = True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2,)\n",
        "\n",
        "print(trainloader)\n",
        "\n",
        "testset = datasets.SVHN(\"/content\", split='test', download = True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "dataSizeConstant = 0.1\n",
        "subset = np.random.permutation([i for i in range(len(trainset))])\n",
        "subTrain = subset[:int(len(trainset) * dataSizeConstant)]\n",
        "\n",
        "print(subset)\n",
        "print(subTrain)\n",
        "\n",
        "subTrainSet = datasets.SVHN(\"/content\", split = \"test\", download = True, transform = transform)\n",
        "subTrainLoader = DataLoader(trainset, batch_size = batch_size, shuffle= False, num_workers= 2, sampler = torch.utils.data.SubsetRandomSampler(subTrain))\n",
        "\n",
        "# define device \n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# data for plotting purposes\n",
        "modelLoss = []\n",
        "\n",
        "# model\n",
        "net = ResNet(BasicBlock, [2,2,2,2])\n",
        "net.to(device)\n",
        "opt = optim.Adam(net.parameters(), lr=0.0001, betas=(0.5, 0.999)) \n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "#training starts\n",
        "\n",
        "epochs = 25\n",
        "\n",
        "# datasetLoader = subTrainLoader\n",
        "def train(datasetLoader):\n",
        "  # file.write(\"Datasize: %d %%\" % (dataSizeConstant))\n",
        "  text = (\"Datasize: \" + str(dataSizeConstant) + \"/n\")\n",
        "  file.write(text)\n",
        "\n",
        "  net.train()\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(datasetLoader, 0):\n",
        "      dataiter = iter(datasetLoader)\n",
        "      inputs, labels = dataiter.next()\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # print(inputs)\n",
        "      # print(labels)\n",
        "\n",
        "      opt.zero_grad()\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      # print(outputs)\n",
        "      pdb.set_trace()\n",
        "      modelLoss = criterion(outputs, labels) # error line\n",
        "      modelLoss.backward()\n",
        "      opt.step()\n",
        "\n",
        "      print(modelLoss)\n",
        "\n",
        "      net.eval()\n",
        "      # accuracy\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total_train += mask.size(0)\n",
        "      correct_train += predicted.eq(mask.data).sum().item()\n",
        "      train_accuracy = 100 * correct_train / total_train\n",
        "      #avg_accuracy = train_accuracy / len(train_loader)                                     \n",
        "      \n",
        "      print('Epoch {}, train Loss: {:.3f}'.format(epoch, loss.item()), \"Training Accuracy: %d %%\" % (train_accuracy))\n",
        "\n",
        "      # # save generated images \n",
        "      if(i % 100 == 0):\n",
        "        text = (\"Train Accuracy: \" + str(train_accuracy))\n",
        "        file.write(text)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Epoch \" + str(epoch) + \"Complete\")\n",
        "    print(\"Loss: \" + str(loss))\n",
        "\n",
        "# validation \n",
        "def validate():\n",
        "  net.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data\n",
        "          outputs = net(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  accuracy = (correct / total) * 100 \n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "      100 * correct / total))\n",
        "\n",
        "  text = (\"Datasize: \" + str(dataSizeConstant) + \"/n\")\n",
        "  file.write(text)\n",
        "  text = (\"Train Accuracy: \" + str(accuracy))\n",
        "  file.write(text)\n",
        "\n",
        "train(subTrainLoader)\n",
        "\n",
        "file.close() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /content/train_32x32.mat\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7fc75c80a710>\n",
            "Using downloaded and verified file: /content/test_32x32.mat\n",
            "[10509 19450  5777 ... 37890 18110 19355]\n",
            "[10509 19450  5777 ... 27735 63159  9328]\n",
            "Using downloaded and verified file: /content/test_32x32.mat\n",
            "> <ipython-input-2-16112d959262>(148)train()\n",
            "-> modelLoss = criterion(outputs, labels) # error line\n",
            "(Pdb) type(outputs)\n",
            "<class 'tuple'>\n",
            "(Pdb) type(labels)\n",
            "<class 'torch.Tensor'>\n",
            "(Pdb) modelLoss = criterion((outputs, 10), labels)\n",
            "*** AttributeError: 'tuple' object has no attribute 'log_softmax'\n",
            "(Pdb) input = torch.randn(3, 5, requires_grad=True)\n",
            "(Pdb) modelLoss = criterion(input, labels)\n",
            "*** ValueError: Expected input batch_size (3) to match target batch_size (64).\n",
            "(Pdb) input = torch.randn(64, 5, requires_grad = True)\n",
            "(Pdb) modelLoss = criterion(input, labels)\n",
            "*** RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_nll_loss_forward\n",
            "(Pdb) input = torch.randn(3, 5, requires_grad=True).cuda()\n",
            "(Pdb) modelLoss = criterion(input, labels)\n",
            "*** ValueError: Expected input batch_size (3) to match target batch_size (64).\n",
            "(Pdb) input = torch.randn(64, 5, requires_grad=True).cuda()\n",
            "(Pdb) modelLoss = criterion(input, labels)\n",
            "(Pdb) print(modelLoss)\n",
            "tensor(2.1394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "(Pdb) modelLoss.backward\n",
            "<bound method Tensor.backward of tensor(2.1394, device='cuda:0', grad_fn=<NllLossBackward>)>\n",
            "(Pdb) modelLoss.backward()\n",
            "(Pdb) opt.step()\n",
            "(Pdb) print(modelLoss)\n",
            "tensor(2.1394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "(Pdb) net.eval()\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "(Pdb) _, predicted = torch.max(outputs.data, 1)\n",
            "*** AttributeError: 'tuple' object has no attribute 'data'\n",
            "--KeyboardInterrupt--\n",
            "--KeyboardInterrupt--\n",
            "--KeyboardInterrupt--\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}